{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"},"colab":{"name":"inceptionv3_images_eval.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"DGiW5bnvsRf8","executionInfo":{"status":"ok","timestamp":1618686859566,"user_tz":360,"elapsed":783,"user":{"displayName":"Andrés Gómez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4WHg4h7VeESmNjKS7HAkqWLka64Djn3J6qsj4=s64","userId":"07812699433280993503"}}},"source":["# Perform necessary imports\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","import time\n","import os\n","import glob\n","import torch\n","from collections import OrderedDict\n","from torchvision import transforms, models\n","import PIL\n","import cv2"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BFyTKyNL8mX7"},"source":["Below we determine the path to load the images to test from. When using collab, we need to mound the Google Drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7RneFDP7vytv","executionInfo":{"status":"ok","timestamp":1618686859580,"user_tz":360,"elapsed":789,"user":{"displayName":"Andrés Gómez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4WHg4h7VeESmNjKS7HAkqWLka64Djn3J6qsj4=s64","userId":"07812699433280993503"}},"outputId":"79ac3af9-adb0-4015-fb46-d36bc72ae91f"},"source":["# Set this flag to indicate if we are using Google Collab for the training process\n","using_collab = True\n","if using_collab:\n","  # We are going to mount google drive to interface with the dataset\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  # Ensure the dataset is uploaded to the next location in your google drive account\n","  dataset_dir = '/content/drive/My Drive/Colab Notebooks/dataset'\n","else:\n","  # We are not using collab. Running in the local computer instead\n","  # Just give relative path to dataset directory\n","  dataset_dir = '../dataset'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o8orI6NE83q4"},"source":["Below we indicate the name of the classes for which the model was already trained. They mush be in the same order as they were loaded for training"]},{"cell_type":"code","metadata":{"id":"VUot2bNrv3eZ","executionInfo":{"status":"ok","timestamp":1618686859584,"user_tz":360,"elapsed":784,"user":{"displayName":"Andrés Gómez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4WHg4h7VeESmNjKS7HAkqWLka64Djn3J6qsj4=s64","userId":"07812699433280993503"}}},"source":["# Name of the classes to load\n","classes_names = ['BOTTLE_OPENER', 'DINNER_FORK', 'DINNER_KNIFE', 'FISH_SLICE', 'KITCHEN_KNIFE', 'LADLE', \n","                 'POTATO_PEELER', 'SPATULA', 'SPOON', 'WHISK']\n","num_classes = len(classes_names)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H2XkrghF9ETy"},"source":["Below we configure the architecture of the model that was trained. We need to define this since the saved pt file only includes the value of the trained weights and not necessarily the architecture."]},{"cell_type":"code","metadata":{"id":"Ty7hkFLWvD_D","executionInfo":{"status":"ok","timestamp":1618686859996,"user_tz":360,"elapsed":1192,"user":{"displayName":"Andrés Gómez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4WHg4h7VeESmNjKS7HAkqWLka64Djn3J6qsj4=s64","userId":"07812699433280993503"}}},"source":["# Define already trained Inception-v3 model for learning transfer\n","model = models.inception_v3(pretrained=True, aux_logits=False)\n","# Define custom classifier as FCL\n","classifier = torch.nn.Sequential(OrderedDict([('fc1', torch.nn.Linear(2048, 1024)),\n","                                              ('relu1', torch.nn.ReLU()),\n","                                              ('drop1', torch.nn.Dropout(0.2)),\n","                                              ('fc2', torch.nn.Linear(1024, 512)),\n","                                              ('relu2', torch.nn.ReLU()),\n","                                              ('drop2', torch.nn.Dropout(0.2)),\n","                                              ('fc3', torch.nn.Linear(512, num_classes)),\n","                                              ('output', torch.nn.LogSoftmax(dim=1))\n","                                             ]))\n","    \n","# Override classifier in model with our custom FCL\n","model.fc = classifier\n","# Disable gradient in the parameters of the model, since we don't want to train it again\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","# Using an incorrect definition of the model like the one below would cause an error when calling load_state_dict for our .pt saved model\n","# model = models.resnet18(pretrained=True)\n","# model.fc = torch.nn.Linear(512, num_classes)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zlCaJNTx9TR_"},"source":["Below we load the weights from the training process."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HZ3H8YZg0URK","executionInfo":{"status":"ok","timestamp":1618686863551,"user_tz":360,"elapsed":4743,"user":{"displayName":"Andrés Gómez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4WHg4h7VeESmNjKS7HAkqWLka64Djn3J6qsj4=s64","userId":"07812699433280993503"}},"outputId":"b5ef2ff8-3922-4330-e9a3-e13a75308871"},"source":["# Determine device to use (to use GPU if available)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# device = torch.device(\"cpu\")\n","model.to(device)\n","print(\"Using device {}\".format(device))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Using device cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i_f0rgvy0n8d","executionInfo":{"status":"ok","timestamp":1618686863553,"user_tz":360,"elapsed":4738,"user":{"displayName":"Andrés Gómez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4WHg4h7VeESmNjKS7HAkqWLka64Djn3J6qsj4=s64","userId":"07812699433280993503"}},"outputId":"d446bf9f-1848-4747-88ef-8f4bff0076fd"},"source":["# Load trained model\n","model.load_state_dict(torch.load('tl_inceptionv3_model.pt'))"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"jSRBP8EP0hMR","executionInfo":{"status":"ok","timestamp":1618686863555,"user_tz":360,"elapsed":4734,"user":{"displayName":"Andrés Gómez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4WHg4h7VeESmNjKS7HAkqWLka64Djn3J6qsj4=s64","userId":"07812699433280993503"}}},"source":["def pre_process_image(image):\n","  \"\"\"Function to pre-process an image before it can be passed through the model.\"\"\"\n","  # Convert from opencv image array to pillow image\n","  image = PIL.Image.fromarray(image)\n","  # Define necessary transforms to align with what the model expects at the input\n","  test_transforms = transforms.Compose([transforms.Resize((310, 310)),\n","                                      transforms.CenterCrop(299),\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize([0.485, 0.456, 0.406],\n","                                                           [0.229, 0.224, 0.225])])\n","  return test_transforms(image).unsqueeze(0).to(device)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"-HyHwD6quDQ0","executionInfo":{"status":"ok","timestamp":1618686863557,"user_tz":360,"elapsed":4734,"user":{"displayName":"Andrés Gómez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4WHg4h7VeESmNjKS7HAkqWLka64Djn3J6qsj4=s64","userId":"07812699433280993503"}}},"source":["def get_prediction(image):\n","  tensor = pre_process_image(image)\n","  logps = model.forward(tensor)\n","  logsoft_prop, predictions = torch.max(logps, 1)\n","  predicted_class = classes_names[predictions.item()]\n","  prob = torch.exp(logsoft_prop).item()\n","  return prob, predicted_class"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"TEV04z53LJGQ","executionInfo":{"status":"ok","timestamp":1618686863558,"user_tz":360,"elapsed":4729,"user":{"displayName":"Andrés Gómez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4WHg4h7VeESmNjKS7HAkqWLka64Djn3J6qsj4=s64","userId":"07812699433280993503"}}},"source":["# Since we are using our model only for inference, switch to `eval` mode:\n","model.eval();"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lSwthh7e--Sa","executionInfo":{"status":"ok","timestamp":1618686880596,"user_tz":360,"elapsed":21762,"user":{"displayName":"Andrés Gómez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4WHg4h7VeESmNjKS7HAkqWLka64Djn3J6qsj4=s64","userId":"07812699433280993503"}},"outputId":"a36bc132-38d0-4a6a-ced2-3f2783ddb160"},"source":["fails_count = 0\n","passes_count = 0\n","total_fails_count = 0\n","total_passes_count = 0\n","total_elapsed = 0\n","# Determine path to all classes in test directory\n","classes_dirs = sorted(glob.glob(dataset_dir + '/test/*'))\n","\n","# Go through each of the classes\n","for class_dir in classes_dirs:\n","  fails_count = 0\n","  passes_count = 0\n","  class_name = os.path.split(class_dir)[-1]\n","  print(\"Running class {}\".format(class_name))\n","  # Go through each of the test images in this class\n","  for class_img_path in glob.glob(class_dir + \"/*\"):\n","    # Load image file\n","    cv_img = cv2.imread(class_img_path)\n","    # Start benchmark for evaluation\n","    start_time = time.time()\n","    # Perform prediction\n","    prob_class, pred_class = get_prediction(cv_img)\n","    # Finish benchmark\n","    end_time = time.time()\n","    total_elapsed += (end_time - start_time)\n","\n","    # Increase counters for pass/fail\n","    if pred_class == class_name:\n","      passes_count += 1\n","    else:\n","      fails_count += 1\n","\n","  print(\"Class passes_count = {}\".format(passes_count))\n","  print(\"Class fails_count = {}\".format(fails_count))\n","  total_count = passes_count + fails_count\n","  print(\"Class accuracy = {}\\n\".format(100 * passes_count / total_count))\n","  total_fails_count += fails_count\n","  total_passes_count += passes_count\n","\n","print(\"total_passes_count = {}\".format(total_passes_count))\n","print(\"total_fails_count = {}\".format(total_fails_count))\n","total_count = total_passes_count + total_fails_count\n","print(\"accuracy = {}\".format(100 * total_passes_count / total_count))\n","print(\"average prediction time [ms] = {}\".format(1000 * total_elapsed / total_count))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Running class BOTTLE_OPENER\n","Class passes_count = 17\n","Class fails_count = 3\n","Class accuracy = 85.0\n","\n","Running class DINNER_FORK\n","Class passes_count = 18\n","Class fails_count = 2\n","Class accuracy = 90.0\n","\n","Running class DINNER_KNIFE\n","Class passes_count = 13\n","Class fails_count = 7\n","Class accuracy = 65.0\n","\n","Running class FISH_SLICE\n","Class passes_count = 14\n","Class fails_count = 6\n","Class accuracy = 70.0\n","\n","Running class KITCHEN_KNIFE\n","Class passes_count = 20\n","Class fails_count = 0\n","Class accuracy = 100.0\n","\n","Running class LADLE\n","Class passes_count = 15\n","Class fails_count = 5\n","Class accuracy = 75.0\n","\n","Running class POTATO_PEELER\n","Class passes_count = 18\n","Class fails_count = 2\n","Class accuracy = 90.0\n","\n","Running class SPATULA\n","Class passes_count = 15\n","Class fails_count = 5\n","Class accuracy = 75.0\n","\n","Running class SPOON\n","Class passes_count = 20\n","Class fails_count = 0\n","Class accuracy = 100.0\n","\n","Running class WHISK\n","Class passes_count = 18\n","Class fails_count = 2\n","Class accuracy = 90.0\n","\n","total_passes_count = 168\n","total_fails_count = 32\n","accuracy = 84.0\n","average prediction time [ms] = 35.7795512676239\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-ffKfzg1CIgs","executionInfo":{"status":"ok","timestamp":1618686880602,"user_tz":360,"elapsed":21763,"user":{"displayName":"Andrés Gómez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4WHg4h7VeESmNjKS7HAkqWLka64Djn3J6qsj4=s64","userId":"07812699433280993503"}}},"source":[""],"execution_count":10,"outputs":[]}]}